id,paper,category,author,year,conference,attack/defense,method,link,comment
1,Intriguing properties of neural networks,Adversarial Machine Learning,"Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, Rob Fergus",2013,CoRR,Attack,L-BFGS,https://arxiv.org/abs/1312.6199,
2,Adversarial Machine Learning,Adversarial Machine Learning,"Ling Huang, Anthony D. Joseph, Blaine Nelson, Benjamin I. P. Rubinstein, J. D. Tygar",2011,AISec,Introduction,,https://people.eecs.berkeley.edu/~tygar/papers/SML2/Adversarial_AISEC.pdf,
3,Adversarial examples in the physical world,Adversarial Machine Learning,"Alexey Kurakin, Ian J. Goodfellow, Samy Bengio",2016,CoRR,Introduction,,https://arxiv.org/abs/1607.02533,
4,Exploring the space of adversarial images,Adversarial Machine Learning,"Pedro Tabacof, Eduardo Valle",2016,IJCNN,Introduction,,https://ieeexplore.ieee.org/document/7727230/,
5,Analysis of classifiers’ robustness to adversarial perturbations,Adversarial Machine Learning,"A Fawzi, O Fawzi, P Frossard",2015,Machine Learning,Introduction,,https://arxiv.org/abs/1502.02590,
6,Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods,Adversarial Machine Learning,"Nicholas Carlini, David Wagner",2017,AISec,Introduction,,http://arxiv.org/abs/1705.07263,
7,Adversarial machine learning at scale,Adversarial Machine Learning,"Alexey Kurakin, Ian Goodfellow, Samy Bengio",2017,ICLR,Introduction,,https://arxiv.org/pdf/1611.01236.pdf,
8,adversarial examples for generative models,Adversarial Machine Learning,"Jernej Kos, Ian Fischer, Dawn Song",2017,arXiv,Introduction,,https://arxiv.org/abs/1702.06832,
9,Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples,Adversarial Machine Learning,"Nicolas Papernot, Patrick D. McDaniel, Ian J. Goodfellow",2016,CoRR,Introduction,,http://arxiv.org/abs/1605.07277,
10,The Space of Transferable Adversarial Examples,Adversarial Machine Learning,"Florian Tramèr, Nicolas Papernot, Ian J. Goodfellow, Dan Boneh, Patrick D. McDaniel",2017,CoRR,Introduction,,http://arxiv.org/abs/1704.03453,
11,Adversarial Examples that Fool both Human and Computer Vision,Adversarial Machine Learning,"Gamaleldin F. Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot, Alex Kurakin, Ian Goodfellow, Jascha Sohl-Dickstein",2018,CoRR,Introduction,,https://arxiv.org/abs/1802.08195,
12,The Limitations of Deep Learning in Adversarial Settings ,Adversarial Machine Learning,"Nicolas Papernot, Patrick D. McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, Ananthram Swami",2016,EuroS&P,Introduction,,https://doi.org/10.1109/EuroSP.2016.36,
13,Adversarial Examples: Attacks and Defenses for Deep Learning,Adversarial Machine Learning,"Xiaoyong Yuan, Pan He, Qile Zhu, Rajendra Rana Bhat, Xiaolin Li",2017,CoRR,Survey,,http://arxiv.org/abs/1712.07107,
14,Towards the Science of Security and Privacy in Machine Learning,Adversarial Machine Learning,"Nicolas Papernot, Patrick D. McDaniel, Arunesh Sinha, Michael P. Wellman",2016,CoRR,Survey,,http://arxiv.org/abs/1611.03814,
15,Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey,Adversarial Machine Learning,"Naveed Akhtar, Ajmal S. Mian",2018,IEEE Access,Survey,,https://doi.org/10.1109/ACCESS.2018.2807385,
16,Explaining and Harnessing Adversarial Examples ,Adversarial Machine Learning,"Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy",2014,CoRR,Attack,FGSM,http://arxiv.org/abs/1412.6572,
17,Practical Black-Box Attacks against Machine Learning,Adversarial Machine Learning,"Nicolas Papernot, Patrick D. McDaniel, Ian J. Goodfellow, Somesh Jha, Z. Berkay Celik, Ananthram Swami",2017,AisaCCS,Attack,RAND+FGSM,http://doi.acm.org/10.1145/3052973.3053009,
18,Towards Evaluating the Robustness of Neural Networks,Adversarial Machine Learning,"Nicholas Carlini, David A. Wagner",2017,IEEE Symposium on Security and Privacy,Attack,CW-Attack,https://doi.org/10.1109/SP.2017.49,
19,Fooling Vision and Language Models Despite Localization and Attention Mechanism,Adversarial Machine Learning,"Xiaojun Xu, Xinyun Chen, Chang Liu, Anna Rohrbach, Trevor Darrell, Dawn Song
",2018,CVPR,Attack,,http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/3295.pdf,
20,Obfuscated Gradients Give a False Sense of Security : Circumventing Defenses to Adversarial Examples,Adversarial Machine Learning,"Anish Athalye, Nicholas Carlini, David A. Wagner",2018,CoRR,Attack,,http://arxiv.org/abs/1802.00420,Github page : https://github.com/anishathalye/obfuscated-gradients
21,Deep neural networks are easily fooled: High confidence predictions for unrecognizable images,Adversarial Machine Learning,"Anh Mai Nguyen, Jason Yosinski, Jeff Clune",2015,CVPR,Attack,,https://doi.org/10.1109/CVPR.2015.7298640,
22,Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning,Adversarial Machine Learning,"Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, Dawn Song",2017,CoRR,Attack,,http://arxiv.org/abs/1712.05526,
23,Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,Adversarial Machine Learning,"Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru, Bo Li",2018,Oakland ,Attack,,http://arxiv.org/abs/1804.00308,
24,Delving into Transferable Adversarial Examples and Black-box Attacks,Adversarial Machine Learning,"Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song",2016,CoRR,Analysis,,http://arxiv.org/abs/1611.02770,
25,Shielding Google's language toxicity model against adversarial attacks,Adversarial Machine Learning,"Nestor Rodriguez, Sergio Rojas Galeano",2018,CoRR,Attack,,http://arxiv.org/abs/1801.01828,
26,Generating Adversarial Examples with Adversarial Networks,Adversarial Machine Learning,"Chaowei Xiao, Bo Li, Jun-Yan Zhu, Warren He, Mingyan Liu, Dawn Song",2018,CoRR,Attack,,http://arxiv.org/abs/1801.02610,
27,Spatially Transformed Adversarial Examples,Adversarial Machine Learning,"Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, Dawn Song",2018,CoRR,Analysis,,http://arxiv.org/abs/1801.02612,
28,Adversarial Deep Learning for Robust Detection of Binary Encoded Malware,Adversarial Machine Learning,"Alex Huang, Abdullah Al-Dujaili, Erik Hemberg, Una-May O'Reilly",2018,CoRR,Defense,,http://arxiv.org/abs/1801.02950,
29,Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers,Adversarial Machine Learning,"Ji Gao, Jack Lanchantin, Mary Lou Soffa, Yanjun Qi",2018,CoRR,Attack,,http://arxiv.org/abs/1801.04354,
30,Delving into Transferable Adversarial Examples and Black-box Attacks,Adversarial Machine Learning,"Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song",2016,CoRR,Analysis,,http://arxiv.org/abs/1611.02770,
31,Robust Physical-World Attacks on Deep Learning Models,Adversarial Machine Learning,"I Evtimov, K Eykholt, E Fernandes",2017,CoRR,Attack,,https://pdfs.semanticscholar.org/e373/d6275ec975c9c74e35348486d9b262b3ecbd.pdf,
32,Adversarial Perturbations Against Deep Neural Networks for Malware Classification,Adversarial Machine Learning,"Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, Patrick D. McDaniel",2016,CoRR,Attack,,http://arxiv.org/abs/1606.04435,
33,Automatically Evading Classifiers: A Case Study on PDF Malware Classifiers,Adversarial Machine Learning,"Weilin Xu, Yanjun Qi, David Evans",2016,NDSS,Attack,,http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2017/09/automatically-evading-classifiers.pdf,
34,Defensive distillation is not robust to adversarial examples,Adversarial Machine Learning,"Nicholas Carlini, David A. Wagner",2016,CoRR,Attack,,http://arxiv.org/abs/1607.04311,
35,Ensemble Adversarial Training: Attacks and Defenses ,Adversarial Machine Learning,"Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Dan Boneh, Patrick D. McDaniel",2017,CoRR,Attack and Defense,R+FGSM,http://arxiv.org/abs/1705.07204,
36,Towards Deep Learning Models Resistant to Adversarial Attacks,Adversarial Machine Learning,"Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu",2017,CoRR,,PGD,http://arxiv.org/abs/1706.06083,
37,Adversarial Patch,Adversarial Machine Learning,"Tom B. Brown, Dandelion Mané, Aurko Roy, Martín Abadi, Justin Gilmer",2017,NIPS,Defense,,http://arxiv.org/abs/1712.09665,
38,Deepfool: a simple and accurate method tofool deep neural networks,Adversarial Machine Learning,"Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard",2016,CVPR,Attack,,https://arxiv.org/abs/1511.04599,
39,Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition,Adversarial Machine Learning,"Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, Michael K. Reiter",2016,CCS,Attack,,http://doi.acm.org/10.1145/2976749.2978392,
40,Invisible Mask: Practical Attacks on Face Recognition with Infrared,Adversarial Machine Learning,"Zhe Zhou, Di Tang, Xiaofeng Wang, Weili Han, Xiangyu Liu, Kehuan Zhang",2018,CoRR,Attack,,http://arxiv.org/abs/1803.04683,
41,Adversarial Generative Nets: Neural Network Attacks on State-of-the-Art Face Recognition,Adversarial Machine Learning,"Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, Michael K. Reiter",2018,CoRR,Attack,,http://arxiv.org/abs/1801.00349,
42,Did you hear that? Adversarial Examples Against Automatic Speech Recognition,Adversarial Machine Learning,"Moustafa Alzantot, Bharathan Balaji, Mani B. Srivastava",2018,CoRR,Attack,,http://arxiv.org/abs/1801.00554,
43,"High Dimensional Spaces, Deep Learning and Adversarial Examples",Adversarial Machine Learning,Simant Dube,2018,CoRR,Attack,,http://arxiv.org/abs/1801.00634,
44,Audio Adversarial Examples: Targeted Attacks on Speech-to-Text,Adversarial Machine Learning,"Nicholas Carlini, David A. Wagner",2018,CoRR,Attack,,http://arxiv.org/abs/1801.01944,
45,Adversarial Vulnerability of Neural Networks Increases With Input Dimension,Adversarial Machine Learning,"Carl-Johann Simon-Gabriel, Yann Ollivier, Bernhard Schölkopf, Léon Bottou, David Lopez-Paz",2018,CoRR,Attack,,http://arxiv.org/abs/1802.01421,
46,DolphinAttack: Inaudible Voice Commands,Adversarial Machine Learning,"Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, Wenyuan Xu",2017,CCS,Attack,,http://doi.acm.org/10.1145/3133956.3134052,
47,Evading Classifiers by Morphing in the Dark,Adversarial Machine Learning,"Hung Dang, Yue Huang, Ee-Chien Chang",2017,CCS,Attack,,http://doi.acm.org/10.1145/3133956.3133978,
48,Adversarial examples for malware detection,Adversarial Machine Learning,,,,Attack,,,
49,Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach,Adversarial Machine Learning,,2018,Computers & Security,Attack,,,
50,Adversarially Robust Malware Detection Using Monotonic Classification,Adversarial Machine Learning,,2018,CODASPY,Defense,,,
51,Adversarial Training Methods for Semi-Supervised Text Classification,Adversarial Machine Learning,,2017,ICLR,,,,
52,Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models,Adversarial Machine Learning,"Pouya Samangouei, Maya Kabkab, Rama Chellappa",2018,CoRR,Defense,,http://arxiv.org/abs/1805.06605,
53,,Adversarial Machine Learning,,,,,,,
54,,Adversarial Machine Learning,,,,,,,
55,Stealing Machine Learning Models via Prediction APIs,Stealing Machine Learning Models,"Florian Tramèr, Fan Zhang, Ari Juels, Michael K. Reiter, Thomas Ristenpart",2016, USENIX Security Symposium,Attack,Probing,https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer,
56,Cracking Classifiers for Evasion: A Case Study on the Google’s Phishing Pages Filter,Stealing Machine Learning Models,,2016,WWW,Attack,Reverse Engineering,https://dl.acm.org/citation.cfm?id=2883060,
57,Stealing Hyperparameters in Machine Learning,Stealing Machine Learning Models,"Binghui Wang, Neil Zhenqiang Gong",2018,CoRR,Attack,Probing,http://arxiv.org/abs/1802.05351,
58,Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures,Stealing Data,"Matt Fredrikson, Somesh Jha, Thomas Ristenpart",2015,CCS,Attack,Stealing Training Data,http://doi.acm.org/10.1145/2810103.2813677,
59,Membership Inference Attacks against Machine Learning Models,Stealing Data,,2017,S&P,Attack,,https://doi.org/10.1109/SP.2017.41,
60,Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning,Stealing Data,,2017,CCS,Attack,GAN,,
61,,,,,,,,,
62,,,,,,,,,
63,,,,,,,,,
64,,,,,,,,,
65,,,,,,,,,
66,,,,,,,,,
67,,,,,,,,,
68,,,,,,,,,
69,,,,,,,,,
70,,,,,,,,,
71,,,,,,,,,
72,,,,,,,,,
73,,,,,,,,,
74,,,,,,,,,
